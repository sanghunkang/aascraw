# aascraw

Aascraw is automated-automated web crawler/scrper library. That is, you can collect your desired dataset only by providing some example data which follows schema of your choice. 







But I want something more "realistic" than  . You know   sometimes raises errors. All of them are too trivial that making noble people smart and educated like you to spend time handling it will be a waste of time.




We know that there are SOME_KINDS_OF_DATA_I_WANT 
 

### Requirement1: The programme can automatically find a path to the elmement of which contains information of interest.

### Requirement2: The programme can automatically find an axis to iterate over.

How can we mechanically check 
- path can be generated by tree-search fashion
-

a tuple of

There are attributes which we desire to be consistent across iteration, and variant across iteration. For example, we expect that 
 
The primary goal is to find a tuple defined by our arbitary configuration, where we can constrain the range of violation of the definition in a limited error bound.

Ther secondary goal is to find such tup

- container-side attributes
    xpath, tag types, classes, id
- content-side attributes
    semantic type of text

we can expect if container-side attributes are similar and content-side attributes are similar, 


The model:






# How it works? 
The Taskgiver
State1      : That we are looking at some webpage
Action1     : Change the webpage we are looking at

The Taskhandler
State2      : Our consistency and variety of data community
Action2     : Decide to include/exclude new datapoint into the community

Reward      : consistency in structure, variance in contents



# Step 2 for requirement 1
Rank based - reinforcement algorithm



# Step2 for requirement 2
Add rank to selected actions






    

# How Taskgiver selects actions?
Unlike evaluating the reward for xpath, which can be calculated by itself, taskgivers reward depends on xpath selection's reward. Analogously speaking, if workers are doing well, that's an evidence that their managers' are doing as well. So we can sensibly reinforce the managers' actions when workers are doing well.

we have to check that our transition policy can bring us 

# Kernels
Kernels are python funtions . It can be simply as counting the length of a string, or as complicated as 




# Versioning Guide
The versions of the library follows MAJOR.MINOR.PATCH scheme. Specfically:

- PATCH - for optimisations and bug-fixes
- MINOR - for changes that affect user interfaces, i.e. public methods, new features.
- MAJOR - no plan yet.



# Experiments
I just started from a random webpage with arbitrary review.